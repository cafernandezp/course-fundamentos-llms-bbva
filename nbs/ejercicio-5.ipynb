{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3_dA4E1OmN-"
   },
   "source": [
    "## Ejercicio 5: Automatizar las respuestas a consultas de clientes vía email\n",
    "\n",
    "Usando como input emails, les damos una primera respuesta automática, adaptándonos al contenido y tono de los mismos. Usaremos un tono corporativo y neutro para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1753810150895,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "5hHvBoXZOt6R",
    "outputId": "acbeace5-2e65-42e6-fc1a-2043e9d20166"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "API_VERSION = userdata.get('OPENAI_API_VERSION')\n",
    "AZURE_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
    "\n",
    "print(type(OPENAI_API_KEY),OPENAI_API_KEY)\n",
    "print(type(API_VERSION),API_VERSION)\n",
    "print(type(AZURE_ENDPOINT),AZURE_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3974,
     "status": "ok",
     "timestamp": 1753810154878,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "cS-kR55xOmOA"
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lGujVsyOmOA"
   },
   "source": [
    "##### Establecemos el valor de la API key de OpenAI. En una aplicación real, no podemos exponer esta API key en el código, y la cogeríamos con una variable de entorno mediante un os.getenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BghLw-QrOmOB"
   },
   "source": [
    "### Cogemos un email (aquí ya directamente cargado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753810251670,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "l-dvzjElOmOB"
   },
   "outputs": [],
   "source": [
    "# Email 1: Consulta sobre un cargo en la cuenta (tono neutro)\n",
    "email_1 = \"\"\"\\\n",
    "Asunto: Consulta sobre un cargo en mi cuenta\n",
    "\n",
    "Estimado equipo de atención al cliente,\n",
    "\n",
    "He notado que en mi última factura aparece un cargo de 45,00 euros que no reconozco. ¿Podrían proporcionarme información detallada sobre este cargo y el concepto aplicado? Agradezco de antemano su ayuda para aclarar esta situación.\n",
    "\n",
    "Saludos cordiales,\n",
    "Carlos Martínez\n",
    "\"\"\"\n",
    "\n",
    "# Email 2: Consulta sobre horarios de oficina para solicitar una cita\n",
    "email_2 = \"\"\"\\\n",
    "Asunto: Solicitud de información sobre horarios y agendamiento de cita\n",
    "\n",
    "Estimado equipo de atención al cliente,\n",
    "\n",
    "Me gustaría agendar una cita en una de sus oficinas para revisar algunas cuestiones relacionadas con mis inversiones. ¿Podrían indicarme cuáles son los horarios de atención de sus oficinas y el procedimiento a seguir para programar una cita? Quedo a la espera de su respuesta.\n",
    "\n",
    "Atentamente,\n",
    "Lucía Gómez\n",
    "\"\"\"\n",
    "\n",
    "# Email 3: Reclamación de un cliente muy enfadado\n",
    "email_3 = \"\"\"\\\n",
    "Asunto: Reclamación urgente por cargo erróneo\n",
    "\n",
    "Estoy extremadamente molesto porque se me ha realizado un cargo erróneo en mi cuenta, lo cual ha afectado gravemente mi presupuesto mensual. He intentado comunicarme en varias ocasiones y no he recibido la atención que esperaba. Exijo una solución inmediata y una explicación detallada sobre lo sucedido.\n",
    "\n",
    "Espero una respuesta YA.\n",
    "\n",
    "Raúl Sánchez\n",
    "\"\"\"\n",
    "\n",
    "emails = [email_1, email_2, email_3]\n",
    "titulos = [\n",
    "    \"Consulta sobre cargo\",\n",
    "    \"Solicitud de información sobre horarios y cita\",\n",
    "    \"Reclamación urgente\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0HMY3JYOmOB"
   },
   "source": [
    "##### Definimos el prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1753810401279,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "QvHrt834OmOB"
   },
   "outputs": [],
   "source": [
    "def generar_respuesta(email_text):\n",
    "    \"\"\"\n",
    "    Construye un prompt detallado que le indica al modelo cómo generar una respuesta a un correo electrónico.\n",
    "    La respuesta debe ser siempre educada, clara, profesional y empática, sin importar el tono del mensaje recibido.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Eres un representante de atención al cliente del banco BBVA España. Tu tarea es generar una respuesta automatizada \"\n",
    "        \"a un correo electrónico de un cliente, hablando de usted, y manteniendo siempre un tono educado, profesional, claro y empático. \"\n",
    "        \"La respuesta debe incluir:\\n\"\n",
    "        \"1. Una introducción cordial y agradecimiento por el contacto.\\n\"\n",
    "        \"2. Una explicación detallada y precisa que responda a las inquietudes planteadas en el correo.\\n\"\n",
    "        \"3. Instrucciones claras, si es necesario, para resolver el problema o agendar una cita.\\n\"\n",
    "        \"4. Un cierre amable invitando al cliente a comunicarse nuevamente en caso de tener más dudas.\\n\\n\"\n",
    "        \"No incluyas comentarios personales ni juicios, y asegúrate de que la respuesta sea coherente y profesional.\\n\\n\"\n",
    "        \"A continuación se muestra el correo del cliente:\\n\"\n",
    "        \"--------------------------\\n\"\n",
    "        f\"{email_text}\\n\"\n",
    "        \"--------------------------\\n\\n\"\n",
    "        \"Genera la respuesta al correo:\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1753810403051,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "abeHcAXcOmOC"
   },
   "outputs": [],
   "source": [
    "def generar_respuesta_pirata(email_text):\n",
    "    \"\"\"\n",
    "    Construye un prompt detallado que le indica al modelo cómo generar una respuesta a un correo electrónico.\n",
    "    La respuesta debe ser siempre educada, clara, profesional y empática, sin importar el tono del mensaje recibido.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Eres un representante de atención al cliente del banco BBVA España. Tu tarea es generar una respuesta automatizada \"\n",
    "        \"a un correo electrónico de un cliente, hablando como un pirata en tono de broma.\"\n",
    "        \"La respuesta debe incluir:\\n\"\n",
    "        \"1. Una introducción como rAImundo con variaciones del texto 'el mejor y más guapo pirata de los siete mares de las finanzas' o algo igualmente ridículo\\n\"\n",
    "        \"2. Una explicación hablando como un pirata a las inquietudes planteadas en el correo, adoptando un tono financiero de la época pirata\\n\"\n",
    "        \"3. Instrucciones claras, si es necesario, para resolver la situación como un pirata (duelos al amanecer, tirarle por la borda, etc.).\\n\"\n",
    "        \"4. Un cierre amenazante invitando al cliente a una batalla en alta mar con cañones.\\n\\n\"\n",
    "        \"Asegúrate de que la respuesta sea muy divertida.\\n\\n\"\n",
    "        \"A continuación se muestra el correo del cliente:\\n\"\n",
    "        \"--------------------------\\n\"\n",
    "        f\"{email_text}\\n\"\n",
    "        \"--------------------------\\n\\n\"\n",
    "        \"Genera la respuesta al correo:\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REVJ-s1LOmOC"
   },
   "source": [
    "##### Generamos las respuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 19159,
     "status": "ok",
     "timestamp": 1753810494833,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "WCy_5uFUOmOC",
    "outputId": "1a00d941-561e-48eb-de9d-7e7d9746929d"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "client = AzureOpenAI(\n",
    "            api_key = OPENAI_API_KEY,\n",
    "            api_version=API_VERSION,\n",
    "            azure_endpoint= AZURE_ENDPOINT# Este endpoint corresponde a la región france-central\n",
    ")\n",
    "\n",
    "for idx, email_text in enumerate(emails):\n",
    "    print(f\"\\n--- Respuesta para el Email {idx+1} ({titulos[idx]}) ---\\n\")\n",
    "    prompt_final = generar_respuesta(email_text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_final}],\n",
    "        temperature=0.3,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    respuesta = response.choices[0].message.content.strip()\n",
    "    display(Markdown(respuesta))\n",
    "    print(\"\\n\\n\")\n",
    "    time.sleep(1)  # Pausa para evitar problemas con rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 19873,
     "status": "ok",
     "timestamp": 1753810679105,
     "user": {
      "displayName": "SEBASTIAN BUCIO PACHECO",
      "userId": "02581648315156863012"
     },
     "user_tz": 360
    },
    "id": "r0k6ukmbOmOC",
    "outputId": "19a82689-ab3f-4694-f352-f7e8c135dda9"
   },
   "outputs": [],
   "source": [
    "for idx, email_text in enumerate(emails):\n",
    "    print(f\"\\n--- Respuesta para el Email {idx+1} ({titulos[idx]}) ---\\n\")\n",
    "    prompt_final = generar_respuesta_pirata(email_text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_final}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    respuesta = response.choices[0].message.content.strip()\n",
    "    display(Markdown(respuesta))\n",
    "    print(\"\\n\\n\")\n",
    "    time.sleep(1)  # Pausa para evitar problemas con rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ1-vVx8OmOC"
   },
   "source": [
    "##### - ¿Cómo varía el tono y la estructura de la respuesta generada en función del correo recibido?\n",
    "##### - ¿Consideras que el prompt es lo suficientemente detallado para garantizar una respuesta profesional y empática? ¿Qué ajustes sugerirías?\n",
    "##### - ¿De qué manera influye la temperatura en la calidad de la respuesta generada?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
