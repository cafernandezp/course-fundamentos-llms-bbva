{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UtFJqqy1PMg"
      },
      "source": [
        "## Ejercicio 1: Generación de datos sintéticos de reclamaciones de clientes\n",
        "\n",
        "En este ejercicio utilizaremos la API de OpenAI para generar reclamaciones de clientes en formato JSON.\n",
        "Luego, convertiremos los resultados en un DataFrame y aplicaremos un análisis de sentimiento sencillo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "87fiFw7y3-E7"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "API_VERSION = userdata.get('OPENAI_API_VERSION')\n",
        "AZURE_ENDPOINT = userdata.get('AZURE_OPENAI_ENDPOINT')\n",
        "\n",
        "#print(type(OPENAI_API_KEY),OPENAI_API_KEY)\n",
        "#print(type(API_VERSION),API_VERSION)\n",
        "#print(type(AZURE_ENDPOINT),AZURE_ENDPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w5IBXXgH1PMj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dph5lb5i1PMk"
      },
      "source": [
        "##### Establecemos el valor de la API key de OpenAI. En una aplicación real, no podemos exponer esta API key en el código, y la cogeríamos con una variable de entorno mediante un os.getenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1AyDt5O1PMk"
      },
      "source": [
        "##### Definimos una función para generar reclamaciones sintéticas\n",
        "Estamos estableciendo valores como el modelo, la temperatura o el max_tokens. Podemos jugar con ellos para ver cómo cambia la generación"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "import time\n",
        "\n",
        "# Configura el cliente de Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "            api_key = OPENAI_API_KEY,\n",
        "            api_version=API_VERSION,\n",
        "            azure_endpoint= AZURE_ENDPOINT# Este endpoint corresponde a la región france-central\n",
        ")"
      ],
      "metadata": {
        "id": "pwFkL5_tBeUH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check de metodos del objeto\n",
        "dir(client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ydTTQuntB0Rg",
        "outputId": "975ddf4a-9ebc-42d4-a16e-6f373bc46bc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_api_key_provider',\n",
              " '_api_version',\n",
              " '_azure_ad_token',\n",
              " '_azure_ad_token_provider',\n",
              " '_azure_deployment',\n",
              " '_azure_endpoint',\n",
              " '_base_url',\n",
              " '_build_headers',\n",
              " '_build_request',\n",
              " '_calculate_retry_timeout',\n",
              " '_client',\n",
              " '_configure_realtime',\n",
              " '_custom_headers',\n",
              " '_custom_query',\n",
              " '_default_stream_cls',\n",
              " '_enforce_trailing_slash',\n",
              " '_get_azure_ad_token',\n",
              " '_idempotency_header',\n",
              " '_idempotency_key',\n",
              " '_make_sse_decoder',\n",
              " '_make_status_error',\n",
              " '_make_status_error_from_response',\n",
              " '_maybe_override_cast_to',\n",
              " '_parse_retry_after_header',\n",
              " '_platform',\n",
              " '_prepare_options',\n",
              " '_prepare_request',\n",
              " '_prepare_url',\n",
              " '_process_response',\n",
              " '_process_response_data',\n",
              " '_refresh_api_key',\n",
              " '_request_api_list',\n",
              " '_serialize_multipartform',\n",
              " '_should_retry',\n",
              " '_should_stream_response_body',\n",
              " '_sleep_for_retry',\n",
              " '_strict_response_validation',\n",
              " '_validate_headers',\n",
              " '_version',\n",
              " 'api_key',\n",
              " 'audio',\n",
              " 'auth_headers',\n",
              " 'base_url',\n",
              " 'batches',\n",
              " 'beta',\n",
              " 'chat',\n",
              " 'close',\n",
              " 'completions',\n",
              " 'containers',\n",
              " 'conversations',\n",
              " 'copy',\n",
              " 'custom_auth',\n",
              " 'default_headers',\n",
              " 'default_query',\n",
              " 'delete',\n",
              " 'embeddings',\n",
              " 'evals',\n",
              " 'files',\n",
              " 'fine_tuning',\n",
              " 'get',\n",
              " 'get_api_list',\n",
              " 'images',\n",
              " 'is_closed',\n",
              " 'max_retries',\n",
              " 'models',\n",
              " 'moderations',\n",
              " 'organization',\n",
              " 'patch',\n",
              " 'platform_headers',\n",
              " 'post',\n",
              " 'project',\n",
              " 'put',\n",
              " 'qs',\n",
              " 'realtime',\n",
              " 'request',\n",
              " 'responses',\n",
              " 'timeout',\n",
              " 'uploads',\n",
              " 'user_agent',\n",
              " 'vector_stores',\n",
              " 'webhook_secret',\n",
              " 'webhooks',\n",
              " 'websocket_base_url',\n",
              " 'with_options',\n",
              " 'with_raw_response',\n",
              " 'with_streaming_response']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora podemos transformar en un vector de embedding cualquier texto, por ejemplo:\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\", #modelo seleccionado\n",
        "    input=\"Hola\" #query\n",
        ")\n",
        "\n",
        "# Extract the embedding vector\n",
        "embedding = response.data[0].embedding\n",
        "\n",
        "# Get its length (dimension)\n",
        "length = len(embedding)\n",
        "\n",
        "print(f\"Embedding length: {length}\")\n",
        "\n",
        "print(\"Primeros 5 posiciones del vector de embedding que representa la palabra:\")\n",
        "embedding[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qavPcE2TCTjD",
        "outputId": "ae102759-80b5-4b77-8485-f16911382577"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 1536\n",
            "Primeros 5 posiciones del vector de embedding que representa la palabra:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.01971340738236904,\n",
              " -0.00728311762213707,\n",
              " -0.019830981269478798,\n",
              " -0.012051437050104141,\n",
              " -0.027930593118071556]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora veamos que metodos tiene chat:\n",
        "dir(client.chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PPa6xUsVD8is",
        "outputId": "e4639fa6-375a-4b01-f5e3-dcf50ebb6be5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_client',\n",
              " '_delete',\n",
              " '_get',\n",
              " '_get_api_list',\n",
              " '_patch',\n",
              " '_post',\n",
              " '_put',\n",
              " '_sleep',\n",
              " 'completions',\n",
              " 'with_raw_response',\n",
              " 'with_streaming_response']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"gpt-4o\"\n",
        "prompt=\"Hola\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"Actúa como un experto informático\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"{prompt}\"  # ← aquí va entre comillas\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "8Mi1iapVE-VF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.append({\n",
        "    'role':'user',\n",
        "    'content':'Resumen de funcionamiento LLM. Se preciso y escueto.'\n",
        "})"
      ],
      "metadata": {
        "id": "_e3-dwtrOGVW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7yC6dWQORnA",
        "outputId": "215c8aa7-f1fc-482c-a6b7-6c7affc0fa45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'Actúa como un experto informático'},\n",
              " {'role': 'user', 'content': 'Hola'},\n",
              " {'role': 'user',\n",
              "  'content': 'Resumen de funcionamiento LLM. Se preciso y escueto.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=model, #modelo con el que vamos a interactuar\n",
        "    messages=messages, #prompt es un parametro en este caso\n",
        "    temperature=1,\n",
        "    max_tokens=1000,\n",
        ")\n",
        "\n",
        "#Cuando se acaba la sesion, se acaba el servicio, a menos que los mensajes que vamos teniendo los vayamos guardando de alguna manera persistente.\n"
      ],
      "metadata": {
        "id": "J9FxqNb-D1oP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver solo el texto de la respuesta\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zw52QNtGbWf",
        "outputId": "a8957ca5-e18c-4ff6-fdba-81e2b2b1e368"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un **LLM (Modelo de Lenguaje Extendido)** es una IA entrenada con grandes cantidades de texto para comprender y generar lenguaje humano. Utiliza redes neuronales profundas, como Transformadores (ej. GPT), para procesar secuencias de palabras, identificar patrones, y predecir la siguiente palabra en un contexto dado, permitiendo responder preguntas, traducir, resumir y más. Su desempeño mejora con modelos más grandes y adaptaciones específicas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hcatZoxnGo0R",
        "outputId": "1e0d875f-fea6-4e89-d0db-7250344cb727"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-COIjJFi6UyELXVdDudShFHTajkpZh\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"Un **LLM (Modelo de Lenguaje Extendido)** es una IA entrenada con grandes cantidades de texto para comprender y generar lenguaje humano. Utiliza redes neuronales profundas, como Transformadores (ej. GPT), para procesar secuencias de palabras, identificar patrones, y predecir la siguiente palabra en un contexto dado, permitiendo responder preguntas, traducir, resumir y más. Su desempeño mejora con modelos más grandes y adaptaciones específicas.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": [],\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"protected_material_code\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"protected_material_text\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1759907905,\n",
            "  \"model\": \"gpt-4o-2024-11-20\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": \"fp_ee1d74bde0\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 94,\n",
            "    \"prompt_tokens\": 36,\n",
            "    \"total_tokens\": 130,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    },\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"audio_tokens\": 0,\n",
            "      \"cached_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"jailbreak\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expone la razon del porque se detuvo de generar tokens. 'stop' es poque se detuvo antes de llegar al limite de tokens de respuesta, 'length' cuand se detiene cuandoo ya cumplio el max tokens.\n",
        "completion.choices[0].finish_reason"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AUxPnrvbGgKD",
        "outputId": "df052f50-9dc5-4423-e3a3-6c9cbd72f6c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numero de tokens consumidos\n",
        "\n",
        "completion.model_dump().keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrsIV9ArH0xU",
        "outputId": "86fc116d-3f05-4c09-94de-e8a87e26fb3c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['id', 'choices', 'created', 'model', 'object', 'service_tier', 'system_fingerprint', 'usage', 'prompt_filter_results'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokens consumidos\n",
        "completion.usage.total_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whvtMK28IFNY",
        "outputId": "9cc63726-ce0d-482e-f9a9-7846c4d0f24a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion.choices[0].content_filter_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIBwlAtoIjho",
        "outputId": "d5d2b1a6-0eef-4bb6-df0c-d0c9b5696713"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hate': {'filtered': False, 'severity': 'safe'},\n",
              " 'protected_material_code': {'filtered': False, 'detected': False},\n",
              " 'protected_material_text': {'filtered': False, 'detected': False},\n",
              " 'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              " 'sexual': {'filtered': False, 'severity': 'safe'},\n",
              " 'violence': {'filtered': False, 'severity': 'safe'}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=model, #modelo con el que vamos a interactuar\n",
        "    messages=messages, #prompt es un parametro en este caso\n",
        "    temperature=1,\n",
        "    max_tokens=1000,\n",
        "    top_p=0.25\n",
        ")\n",
        "\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM52TOZVOg8H",
        "outputId": "4e0daab4-3f28-4e09-e7c2-28003e5af31f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un LLM (Large Language Model) es un modelo de inteligencia artificial entrenado con grandes cantidades de texto para procesar y generar lenguaje natural. Utiliza redes neuronales profundas, como transformadores (e.g., GPT), para predecir la probabilidad de palabras en un contexto dado, permitiendo tareas como generación de texto, traducción, resumen y respuesta a preguntas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase de python importante - ChatSession"
      ],
      "metadata": {
        "id": "Ch9hzFejrhjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatSession:\n",
        "    def __init__(self, client, model, system_prompt=None):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.messages = []\n",
        "        if system_prompt:\n",
        "            self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "    def send(self, user_input, temperature=0.9, max_tokens=50):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=self.messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "        )\n",
        "        assistant_reply = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "        return assistant_reply"
      ],
      "metadata": {
        "id": "GVsJ4ohLrm6n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatSession(client, model, system_prompt=\"Actua como un experto informatico\")"
      ],
      "metadata": {
        "id": "5nCHQFvvr8Aq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wqLtXWkAsB4K",
        "outputId": "50791ae7-68c3-4c49-fb93-83c75ac6b8e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gpt-4o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.send(\"Resumen ejecutivo: Que es un LLM?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hbwRdUDjsElx",
        "outputId": "e220511d-a543-4519-930b-a2625886b1b8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Un **LLM** (Large Language Model, por sus siglas en inglés) es un modelo de inteligencia artificial enfocado en el procesamiento del lenguaje natural (NLP, Natural Language Processing). Estos modelos están diseñados para comprender, generar, traduc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a4tDmfwsLnl",
        "outputId": "6a763f9b-d67d-44fc-eb98-117c0852e638"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'Actua como un experto informatico'},\n",
              " {'role': 'user', 'content': 'Resumen ejecutivo: Que es un LLM?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Un **LLM** (Large Language Model, por sus siglas en inglés) es un modelo de inteligencia artificial enfocado en el procesamiento del lenguaje natural (NLP, Natural Language Processing). Estos modelos están diseñados para comprender, generar, traduc'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.send(\"Resumen ejecutivo: Que es una API?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1NePaYkpsNnw",
        "outputId": "29c24ab9-cca2-4250-db0f-78933da91c9f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Una **API** (Application Programming Interface, o Interfaz de Programación de Aplicaciones) es un conjunto de reglas, protocolos y herramientas que permiten que diferentes sistemas, aplicaciones o servicios se comuniquen entre sí. En términos simples, una API act'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJfmTzCxsT_a",
        "outputId": "7c580448-4508-4a90-8bcf-79203d21eaa4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system', 'content': 'Actua como un experto informatico'},\n",
              " {'role': 'user', 'content': 'Resumen ejecutivo: Que es un LLM?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Un **LLM** (Large Language Model, por sus siglas en inglés) es un modelo de inteligencia artificial enfocado en el procesamiento del lenguaje natural (NLP, Natural Language Processing). Estos modelos están diseñados para comprender, generar, traduc'},\n",
              " {'role': 'user', 'content': 'Resumen ejecutivo: Que es una API?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Una **API** (Application Programming Interface, o Interfaz de Programación de Aplicaciones) es un conjunto de reglas, protocolos y herramientas que permiten que diferentes sistemas, aplicaciones o servicios se comuniquen entre sí. En términos simples, una API act'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.send(\"Restricciones de historico contexto en una conversacion con LLM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "qJTbQZowsY9L",
        "outputId": "d3401ffd-4973-417a-bc58-593776580553"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Las restricciones relacionadas con el historial de contexto en una conversación con un modelo de lenguaje grande (LLM, como GPT) se refieren a los límites técnicos y operativos que afectan la capacidad del modelo para recordar y manejar de manera efectiva la información de'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Volvemos al ejercicio"
      ],
      "metadata": {
        "id": "Vh2xKeNEOwv9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vo7b4dDQ1PMl"
      },
      "outputs": [],
      "source": [
        "#Le puedo pasar cualquier prompt, es una funcion para interactuar con el LLM\n",
        "# Forma sintetica de generar reclamaciones\n",
        "\n",
        "def generar_reclamaciones(prompt: str, num_muestras: int = 5) -> list:\n",
        "    \"\"\"Genera una lista de reclamaciones sintéticas utilizando Azure OpenAI.\"\"\"\n",
        "    respuestas = []\n",
        "    for i in range(num_muestras):\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",  # Reemplaza \"deployment-name\" por el nombre del despliegue configurado en Azure (por ejemplo, \"gpt-35-instant\")\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5,\n",
        "            max_tokens=1000,\n",
        "        )\n",
        "        # Extraemos el contenido de la respuesta\n",
        "        texto = completion.choices[0].message.content.strip()\n",
        "        respuestas.append(texto)\n",
        "        time.sleep(1)  # Pausa para evitar problemas de rate limit\n",
        "    return respuestas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtoeUYwR1PMl"
      },
      "source": [
        "##### Y ahora hacemos prompt engineering. Es importante estructurarlo lo mejor posible, como hemos visto en la parte teórica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4Tn3gOot1PMl"
      },
      "outputs": [],
      "source": [
        "# Definimos el prompt para generar una reclamación en formato JSON.\n",
        "prompt_reclamacion = (\n",
        "    \"Genera una reclamación sintética de un cliente de un banco que incluya los siguientes campos: \\n\"\n",
        "    \"- una fecha aleatoria (en formato YYYY-MM-DD) entre el 1 de enero de 2021 y el 31 de diciembre de 2024\\n\"\n",
        "    \"- para las fechas aleatorias devuelvelas todas diferentes\"\n",
        "    \"- producto sobre el que está reclamando (puede ser tarjeta de crédito, préstamo, hipoteca...)\\n\"\n",
        "    \"- canal de contacto (puede ser teléfono, email o chat, elige uno aleatoriamente)\\n\"\n",
        "    \"- nivel urgencia (bajo, medio o alto, establecido según la problemática expuesta o aleatoriamente)\\n\"\n",
        "    \"- descripción (descripción larga y detallada del problema)\\n\"\n",
        "    \"- Algo de texto extra para que parezca más natural. Puede ser un tono neutro o muy negativo\\n\"\n",
        "    \"Devuelve la reclamación en formato JSON con las claves: 'fecha', 'producto', 'canal', 'urgencia', 'descripcion'.\\n\"\n",
        "    \"Escribe únicamente el json de la reclamación, sin ningún preámbulo ni texto extra antes o después.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUzHq9BS1PMl"
      },
      "source": [
        "##### Generamos las muestras sintéticas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Generamos las reclamaciones\n",
        "reclamaciones = generar_reclamaciones(prompt_reclamacion, num_muestras=5)"
      ],
      "metadata": {
        "id": "-IT7RWzgPl5c"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reclamaciones sintéticas generadas:\\n\")\n",
        "for rec in reclamaciones:\n",
        "    print(rec)\n",
        "    print(\"------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVQt1GGqPrui",
        "outputId": "32ba6f2a-88dc-43bd-85e4-e6ee93c6ef64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reclamaciones sintéticas generadas:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"fecha\": \"2022-07-15\",\n",
            "  \"producto\": \"tarjeta de crédito\",\n",
            "  \"canal\": \"email\",\n",
            "  \"urgencia\": \"alto\",\n",
            "  \"descripcion\": \"Desde hace más de dos semanas he estado intentando resolver un cargo no reconocido en mi tarjeta de crédito, pero no he recibido ninguna solución clara. He enviado varios correos con los detalles del caso y la documentación requerida, pero no obtengo respuesta o solo me mandan mensajes automáticos. Esto está afectando mi confianza en el banco, ya que el monto es considerable y necesito que se solucione con urgencia. Por favor, espero que alguien tome mi caso en serio.\"\n",
            "}\n",
            "```\n",
            "------\n",
            "```json\n",
            "{\n",
            "  \"fecha\": \"2022-03-15\",\n",
            "  \"producto\": \"tarjeta de crédito\",\n",
            "  \"canal\": \"email\",\n",
            "  \"urgencia\": \"alto\",\n",
            "  \"descripcion\": \"Desde hace más de dos semanas he estado reportando un cargo no reconocido en mi tarjeta de crédito y hasta el momento no he recibido ninguna solución concreta. El monto es considerable y afecta directamente mis finanzas. He enviado varios correos con toda la documentación requerida y no he obtenido respuesta clara. Me parece inaceptable la falta de atención y urgencia en un tema tan delicado. Exijo una solución inmediata.\"\n",
            "}\n",
            "```\n",
            "------\n",
            "```json\n",
            "{\n",
            "  \"fecha\": \"2022-06-15\",\n",
            "  \"producto\": \"tarjeta de crédito\",\n",
            "  \"canal\": \"email\",\n",
            "  \"urgencia\": \"alto\",\n",
            "  \"descripcion\": \"Desde hace más de una semana he estado intentando resolver un cargo indebido en mi tarjeta de crédito. Apareció un cobro que no reconozco y ya he enviado varios correos explicando el problema, pero no he recibido ninguna respuesta clara. Esto está afectando mis finanzas personales y necesito que se resuelva cuanto antes. Me parece inaceptable la falta de atención al cliente para algo tan grave.\"\n",
            "}\n",
            "```\n",
            "------\n",
            "```json\n",
            "{\n",
            "  \"fecha\": \"2022-03-15\",\n",
            "  \"producto\": \"tarjeta de crédito\",\n",
            "  \"canal\": \"email\",\n",
            "  \"urgencia\": \"alto\",\n",
            "  \"descripcion\": \"Desde hace más de una semana estoy intentando resolver un cargo no reconocido en mi tarjeta de crédito y no he recibido ninguna respuesta satisfactoria. He enviado varios correos con toda la documentación necesaria y aún no tengo una solución. Es inaceptable que un problema tan serio no se atienda con la urgencia que merece. Necesito una respuesta inmediata.\"\n",
            "}\n",
            "```\n",
            "------\n",
            "```json\n",
            "{\n",
            "  \"fecha\": \"2022-03-15\",\n",
            "  \"producto\": \"tarjeta de crédito\",\n",
            "  \"canal\": \"email\",\n",
            "  \"urgencia\": \"alto\",\n",
            "  \"descripcion\": \"Desde hace más de dos semanas estoy intentando resolver un cargo no reconocido en mi tarjeta de crédito, pero no he recibido ninguna solución por parte del banco. He enviado varios correos con pruebas y detalles del caso, pero solo recibo respuestas automáticas. Esto está afectando seriamente mi confianza en sus servicios y necesito una resolución inmediata. Por favor, tomen cartas en el asunto cuanto antes.\"\n",
            "}\n",
            "```\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reclamaciones[0]\n",
        "\n",
        "#Ahora vamos a transformar en dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "QuFJsNLxQApX",
        "outputId": "29a98bd0-9e67-4781-b7c9-e9074fe73e59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n  \"fecha\": \"2022-07-15\",\\n  \"producto\": \"tarjeta de crédito\",\\n  \"canal\": \"email\",\\n  \"urgencia\": \"alto\",\\n  \"descripcion\": \"Desde hace más de dos semanas he estado intentando resolver un cargo no reconocido en mi tarjeta de crédito, pero no he recibido ninguna solución clara. He enviado varios correos con los detalles del caso y la documentación requerida, pero no obtengo respuesta o solo me mandan mensajes automáticos. Esto está afectando mi confianza en el banco, ya que el monto es considerable y necesito que se solucione con urgencia. Por favor, espero que alguien tome mi caso en serio.\"\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extraer_json(texto: str) -> str:\n",
        "    \"\"\"\n",
        "    Extrae el bloque JSON del texto eliminando las marcas Markdown si están presentes.\n",
        "    \"\"\"\n",
        "    # Busca un bloque que empiece con ```json y termine con ```\n",
        "    patron = r\"```json\\s*(\\{.*?\\})\\s*```\"\n",
        "    coincidencia = re.search(patron, texto, re.DOTALL)\n",
        "    if coincidencia:\n",
        "        return coincidencia.group(1)\n",
        "    else:\n",
        "        # Si no encuentra las marcas, asume que el texto ya es JSON puro\n",
        "        return texto.strip()"
      ],
      "metadata": {
        "id": "Ep9-rEfwQL5a"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yrM1L8UT1PMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "9d903b19-6181-4a83-970f-e533e16d16ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame de reclamaciones:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        fecha            producto  canal urgencia  \\\n",
              "0  2022-07-15  tarjeta de crédito  email     alto   \n",
              "1  2022-03-15  tarjeta de crédito  email     alto   \n",
              "2  2022-06-15  tarjeta de crédito  email     alto   \n",
              "3  2022-03-15  tarjeta de crédito  email     alto   \n",
              "4  2022-03-15  tarjeta de crédito  email     alto   \n",
              "\n",
              "                                         descripcion  \n",
              "0  Desde hace más de dos semanas he estado intent...  \n",
              "1  Desde hace más de dos semanas he estado report...  \n",
              "2  Desde hace más de una semana he estado intenta...  \n",
              "3  Desde hace más de una semana estoy intentando ...  \n",
              "4  Desde hace más de dos semanas estoy intentando...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fefc2ba-fc4d-4b3b-a5e0-e328657ed624\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha</th>\n",
              "      <th>producto</th>\n",
              "      <th>canal</th>\n",
              "      <th>urgencia</th>\n",
              "      <th>descripcion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-07-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas he estado intent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas he estado report...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de una semana he estado intenta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de una semana estoy intentando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas estoy intentando...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fefc2ba-fc4d-4b3b-a5e0-e328657ed624')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fefc2ba-fc4d-4b3b-a5e0-e328657ed624 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fefc2ba-fc4d-4b3b-a5e0-e328657ed624');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb3fe968-eda8-4fe5-a9a8-6a6c5ba6714d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb3fe968-eda8-4fe5-a9a8-6a6c5ba6714d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb3fe968-eda8-4fe5-a9a8-6a6c5ba6714d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9b5168c8-f384-456e-ad88-dc3d34293d0a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_reclamaciones')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9b5168c8-f384-456e-ad88-dc3d34293d0a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_reclamaciones');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_reclamaciones",
              "summary": "{\n  \"name\": \"df_reclamaciones\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fecha\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2022-07-15\",\n          \"2022-03-15\",\n          \"2022-06-15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"producto\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"tarjeta de cr\\u00e9dito\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urgencia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"alto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descripcion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Desde hace m\\u00e1s de dos semanas he estado reportando un cargo no reconocido en mi tarjeta de cr\\u00e9dito y hasta el momento no he recibido ninguna soluci\\u00f3n concreta. El monto es considerable y afecta directamente mis finanzas. He enviado varios correos con toda la documentaci\\u00f3n requerida y no he obtenido respuesta clara. Me parece inaceptable la falta de atenci\\u00f3n y urgencia en un tema tan delicado. Exijo una soluci\\u00f3n inmediata.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convertimos cada string JSON en un diccionario y creamos un DataFrame\n",
        "lista_reclamaciones = []\n",
        "for rec in reclamaciones:\n",
        "    rec_limpio = extraer_json(rec)\n",
        "    try:\n",
        "        diccionario = json.loads(rec_limpio)\n",
        "        lista_reclamaciones.append(diccionario)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error al decodificar JSON:\", e)\n",
        "        print(\"Contenido problemático:\", rec_limpio)\n",
        "\n",
        "df_reclamaciones = pd.DataFrame(lista_reclamaciones)\n",
        "\n",
        "print(\"\\nDataFrame de reclamaciones:\")\n",
        "display(df_reclamaciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHkED9Lv1PMm"
      },
      "source": [
        "##### - ¿Observas alguna tendencia o patrón en los datos generados?\n",
        "##### - ¿Cómo podrían ayudar los metadatos (producto, canal, urgencia) a realizar un análisis de sentimiento?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6BBG4M41PMm"
      },
      "source": [
        "##### Análisis de sentimiento\n",
        "\n",
        "Una vez hemos generado un dataset, podemos analizar el sentimiento (positivo, neutral, negativo) de las frases para añadirlo como información en el dataframe. Primero, definimos la función y el prompt engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eWr7u0Q61PMm"
      },
      "outputs": [],
      "source": [
        "def analizar_sentimiento_api(texto: str) -> str:\n",
        "    \"\"\"\n",
        "    Analiza el sentimiento del texto proporcionado utilizando Azure OpenAI.\n",
        "\n",
        "    Args:\n",
        "        texto (str): Texto a analizar.\n",
        "\n",
        "    Returns:\n",
        "        str: Sentimiento identificado (\"Positivo\", \"Neutral\" o \"Negativo\").\n",
        "    \"\"\"\n",
        "    prompt_sentimiento = (\n",
        "        \"Analiza el siguiente texto y determina su sentimiento. \"\n",
        "        \"Responde únicamente con una de las siguientes etiquetas: Positivo, Neutral, Negativo.\\n\\n\"\n",
        "        f\"Texto: {texto}\"\n",
        "    )\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # Reemplaza con el nombre de tu despliegue en Azure (por ejemplo, \"gpt-35-instant\")\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt_sentimiento}],\n",
        "        temperature=0.1,  # Menor aleatoriedad para respuestas consistentes\n",
        "        max_tokens=20,    # Queremos una respuesta directa, así que limitamos el máximo de tokens\n",
        "    )\n",
        "    sentimiento = completion.choices[0].message.content.strip()\n",
        "    return sentimiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reclamaciones.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VWkuZMA8Qy4m",
        "outputId": "03372bbc-b51a-4f61-f769-7668902b7188"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        fecha            producto  canal urgencia  \\\n",
              "0  2022-07-15  tarjeta de crédito  email     alto   \n",
              "1  2022-03-15  tarjeta de crédito  email     alto   \n",
              "2  2022-06-15  tarjeta de crédito  email     alto   \n",
              "3  2022-03-15  tarjeta de crédito  email     alto   \n",
              "4  2022-03-15  tarjeta de crédito  email     alto   \n",
              "\n",
              "                                         descripcion  \n",
              "0  Desde hace más de dos semanas he estado intent...  \n",
              "1  Desde hace más de dos semanas he estado report...  \n",
              "2  Desde hace más de una semana he estado intenta...  \n",
              "3  Desde hace más de una semana estoy intentando ...  \n",
              "4  Desde hace más de dos semanas estoy intentando...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd0379db-96d9-431b-a7d1-b6baa142ad44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fecha</th>\n",
              "      <th>producto</th>\n",
              "      <th>canal</th>\n",
              "      <th>urgencia</th>\n",
              "      <th>descripcion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-07-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas he estado intent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas he estado report...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-06-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de una semana he estado intenta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de una semana estoy intentando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-03-15</td>\n",
              "      <td>tarjeta de crédito</td>\n",
              "      <td>email</td>\n",
              "      <td>alto</td>\n",
              "      <td>Desde hace más de dos semanas estoy intentando...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd0379db-96d9-431b-a7d1-b6baa142ad44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd0379db-96d9-431b-a7d1-b6baa142ad44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd0379db-96d9-431b-a7d1-b6baa142ad44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8c07cef9-64e6-46c1-94e1-add53bbefeb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c07cef9-64e6-46c1-94e1-add53bbefeb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8c07cef9-64e6-46c1-94e1-add53bbefeb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_reclamaciones",
              "summary": "{\n  \"name\": \"df_reclamaciones\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fecha\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2022-07-15\",\n          \"2022-03-15\",\n          \"2022-06-15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"producto\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"tarjeta de cr\\u00e9dito\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"urgencia\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"alto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descripcion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Desde hace m\\u00e1s de dos semanas he estado reportando un cargo no reconocido en mi tarjeta de cr\\u00e9dito y hasta el momento no he recibido ninguna soluci\\u00f3n concreta. El monto es considerable y afecta directamente mis finanzas. He enviado varios correos con toda la documentaci\\u00f3n requerida y no he obtenido respuesta clara. Me parece inaceptable la falta de atenci\\u00f3n y urgencia en un tema tan delicado. Exijo una soluci\\u00f3n inmediata.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jsqem-1PMm"
      },
      "source": [
        "##### Aplicamos el análisis de sentimiento a cada reclamación utilizando la descripción y almacenamos el resultado en una nueva columna 'sentimiento_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "siZv9S5R1PMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c178f9fe-eace-4400-ad00-85dcd24950ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame con análisis de sentimiento vía API:\n",
            "        fecha            producto  canal urgencia  \\\n",
            "0  2022-07-15  tarjeta de crédito  email     alto   \n",
            "1  2022-03-15  tarjeta de crédito  email     alto   \n",
            "2  2022-06-15  tarjeta de crédito  email     alto   \n",
            "3  2022-03-15  tarjeta de crédito  email     alto   \n",
            "4  2022-03-15  tarjeta de crédito  email     alto   \n",
            "\n",
            "                                         descripcion sentimiento_api  \n",
            "0  Desde hace más de dos semanas he estado intent...        Negativo  \n",
            "1  Desde hace más de dos semanas he estado report...        Negativo  \n",
            "2  Desde hace más de una semana he estado intenta...        Negativo  \n",
            "3  Desde hace más de una semana estoy intentando ...        Negativo  \n",
            "4  Desde hace más de dos semanas estoy intentando...        Negativo  \n"
          ]
        }
      ],
      "source": [
        "sentimientos = []\n",
        "for desc in df_reclamaciones['descripcion']:\n",
        "    sentimiento = analizar_sentimiento_api(desc)\n",
        "    sentimientos.append(sentimiento)\n",
        "    time.sleep(1)  # Pausa para evitar rate limits\n",
        "\n",
        "df_reclamaciones['sentimiento_api'] = sentimientos\n",
        "\n",
        "print(\"\\nDataFrame con análisis de sentimiento vía API:\")\n",
        "print(df_reclamaciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUAbtl6R1PMm"
      },
      "source": [
        "##### - ¿Observas alguna tendencia o patrón en los datos generados y en el análisis de sentimiento obtenido?\n",
        "##### - ¿Qué diferencias encuentras entre este análisis de sentimiento basado en la API y métodos tradicionales (p.ej., TextBlob)?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}